### 2016-6（Ⅰ） 四级

#### 原文

1. As Artificial Intelligence (AI) becomes increasingly sophisticated, there are growing concerns that robots could become a threat. This danger can be avoided, according to computer science professor Stuart Russell, if we figure out how to turn human values into a programmable code.

2. Russell argues that as robots take on more complicated tasks, it's necessary to translate our morals into AI language.

3. For example, if a robot does chores around the house, you wouldn't want it to put the pet cat in the oven to make dinner for the hungry children. "You would want that robot preloaded with a good set of values," said Russell.

4. Some robots are already programmed with basic human values. For example, mobile robots have been programmed to keep a comfortable distance from humans. Obviously there are cultural differences, but if you were talking to another person and they came up close in your personal space, you wouldn't think that's the kind of thing a properly brought-up person would do.

5. It will be possible to create more sophisticated moral machines, if only we can find a way to set out human values as clear rules.

6. Robots could also learn values from drawing patterns from large sets of data on human behavior. They are dangerous only if programmers are careless.

7. The biggest concern with robots going against human values is that human beings fail to do sufficient testing and they've produced a system that will break some kind of taboo (禁忌).

8. One simple check would be to program a robot to check the correct course of action with a human when presented with an unusual situation.

9. If the robot is unsure whether an animal is suitable for the microwave, it has the opportunity to stop, send out beeps (嘟嘟声), and ask for directions from a human. If we humans aren't quite sure about a decision, we go and ask somebody else.

10. The most difficult step in programming values will be deciding exactly what we believe is moral, and how to create a set of ethical rules. But if we come up with an answer, robots could be good for humanity.



46. What does the author say about the threat of robots?

A) It may constitute a challenge to computer programmers.

B) It accompanies all machinery involving high technology.

C) It can be avoided if human values are translated into their language.

D) It has become an inevitable peril as technology gets more sophisticated.



47. What would we think of a person who invades our personal space according to the author? 

A) They are aggressive.

B) They are outgoing.

C) They are ignorant.

D) They are ill-bred.



48. How do robots learn human values?  

A) By interacting with humans in everyday life situations.

B) By following the daily routines of civilized human beings.

C) By picking up patterns from massive data on human behavior.

D) By imitating the behavior of properly brought-up human beings.



49. What will a well-programmed robot do when facing an unusual situation?   

A) Keep a distance from possible dangers.

B) Stop to seek advice from a human being.

C) Trigger its built-in alarm system at once.

D) Do sufficient testing before taking action.



50. What is most difficult to do when we turn human values into a programmable code?   

A) Determine what is moral and ethical.

B) Design some large-scale experiments.

C) Set rules for man-machine interaction.

D) Develop a more sophisticated program.

#### 翻译

1. As Artificial Intelligence (AI) becomes increasingly sophisticated, there are growing concerns that （46）**robots could become a threat. This danger can be avoided, according to computer science professor Stuart Russell, if we figure out how to turn human values into a programmable code.**

2. Russell argues that as robots take on more complicated tasks, it's necessary to translate our morals into AI language.

3. For example, if a robot does chores around the house, you wouldn't want it to put the pet cat in the oven to make dinner for the hungry children. "You would want that robot preloaded with a good set of values," said Russell.

4. Some robots are already programmed with basic human values. For example, mobile robots have been programmed to keep a comfortable distance from humans. (47)**Obviously there are cultural differences, but if you were talking to another person and they came up close in your personal space, you wouldn't think that's the kind of thing a properly brought-up person would do.**

5. It will be possible to create more sophisticated moral machines, if only we can find a way to set out human values as clear rules.

6. (48)**Robots could also learn values from drawing patterns from large sets of data on human behavior. They are dangerous only if programmers are careless.**

7. The biggest concern with robots going against human values is that human beings fail to do sufficient testing and they've produced a system that will break some kind of taboo (禁忌).

8. (49)**One simple check would be to program a robot to check the correct course of action with a human when presented with an unusual situation.**

9. If the robot is unsure whether an animal is suitable for the microwave, it has the opportunity to stop, send out beeps (嘟嘟声), **and ask for directions from a human.** If we humans aren't quite sure about a decision, we go and ask somebody else.

10. (50)**The most difficult step in programming values will be deciding exactly what we believe is moral, and how to create a set of ethical rules. But if we come up with an answer, robots could be good for humanity.**


#### 翻译

随着人工智能（AI）变得越来越复杂，人们越来越担心机器人可能会成为一种威胁。计算机学教授Stuart Russell认为，如果我们弄清楚如何将人类价值转化为可编程代码，就可以避免这种危险。

拉塞尔认为，随着机器人承担更复杂的任务，有必要将我们的道德转化为人工智能语言。

例如，如果一个机器人在房子周围做家务，你就不希望它把宠物猫放在烤箱里为饥饿的孩子做晚餐。 “你会希望机器人预装好一套好的价值观，”拉塞尔说。

一些机器人已经编程了基本的人类价值观。例如，移动机器人已被编程为与人保持舒适的距离。显然文化存在差异，但如果你和另一个人交谈并且他走得离你的个人空间很近，你不会认为这是有良好教养的人会做的事情。

只要我们能找到一种将人类价值观作为明确规则的方法，就有可能创造出更复杂的道德机器。

机器人还可以从大量关于人类行为的数据中绘制图案来学习价值。只有程序员不小心，它们才是危险的。

机器人违背人类价值观的最大担忧是，人类未能进行足够的测试，而且他们已经制造出一种能够打破某种禁忌的制度。

一个简单的检查是对机器人进行编程，以便在出现异常情况时与人类确认正确的行动方案。

如果机器人不确定动物是否适合微波炉，它就有机会停下来，发出嘟嘟声（嘟嘟声），并询问人类的指示。如果我们人类对决定不太确定，我们会去问别人。

编程价值观中最困难的一步将是确切地决定我们认为是道德的，以及如何创建一套道德规则。但如果我们得出答案，机器人可能对人类有益。

